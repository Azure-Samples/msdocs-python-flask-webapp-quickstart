{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e2da07d-a676-4ec8-b98b-3223a3b0ea0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Overall Architecture Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2061c580-53b6-4224-aeeb-2916da6c5fa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](./DFCI_Demo_App_Architecture.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b88ed5e-e5c7-4ad8-b7c2-b003c9e31884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Test OAuth 2.0 Authorization and API Request\n",
    "\n",
    "### At this section, we want to first test if the OAuth 2.0 server is working or not. We wont involve the \"Databricks Model Serving Endpoint and Gateway\" module for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7def3842-4a01-4def-be7e-f87a54646bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create your secret scope using \"Databricks Secret Vault\", for example,\n",
    "1. Create your secret scope first for a specific workspace profile: `databricks secrets create-scope yyang_secret_scope`\n",
    "2. Put your secret key and value: `databricks secrets put-secret yyang_secret_scope pat`, here `pat` is your key\n",
    "    - then input the value following the prompt or editor edit/save\n",
    "3. (optional) you can also save other key:value pair like databricks_host and workspace_id. `databricks secrets put-secret yyang_secret_scope db_host`\n",
    "\n",
    "\n",
    "Now you are done.\n",
    "\n",
    "\n",
    "\n",
    "Ref: https://learn.microsoft.com/en-us/azure/databricks/security/secrets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880b3fcd-4fb5-43b4-a513-6147cda38390",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "setup secret without showing"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: use db keyvault to save below\n",
    "\n",
    "client_secret = 'fill-your-secret-here' # web app \"dfci-demo-app/fernet-w-api\" (slot) registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18c5fcd3-18f5-4173-9c0f-f7fdc29d0f65",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "fetch OAuth2 token using client credentials from EntryID"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "tenant_id = '9f37a392-f0ae-4280-9796-f1864a10effc'\n",
    "# client_id = '67ed6fea-e8ec-4d56-880c-f59688aa2c48' # web app \"dfci-demo-app\"\n",
    "client_id = '610ad44b-74fc-4f7e-b385-cc8c93a8423b' # web app \"dfci-demo-app/fernet-w-api\" (slot)\n",
    "# client_id = '78061f18-2c8b-4c8d-95f7-c9527a75deb3' # APIM\n",
    "# scope = 'api://67ed6fea-e8ec-4d56-880c-f59688aa2c48/.default' # dfci-demo-app\"\n",
    "scope = 'api://610ad44b-74fc-4f7e-b385-cc8c93a8423b/.default' # web app \"dfci-demo-app/fernet-w-api\" (slot)\n",
    "# scope = 'api://78061f18-2c8b-4c8d-95f7-c9527a75deb3/.default' # APIM\n",
    "\n",
    "url = f'https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token'\n",
    "headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'scope': scope\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=data)\n",
    "print(response.status_code)\n",
    "print(response.json())\n",
    "token = response.json().get('access_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a162664c-c1a0-4f11-ba5b-a9a34871e8f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42424abf-905f-43c4-983b-594dba0a0cb7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check API response with authorization header"
    }
   },
   "outputs": [],
   "source": [
    "# headers = {'Authorization': f'Bearer {token + \"xxx\"}'} # this is for testing if bad token will lead to failure as expected\n",
    "headers = {'Authorization': f'Bearer {token}'} # if you see status 200, that means succesful.\n",
    "response = requests.get('https://dfci-api-management.azure-api.net/api2/v1/', headers=headers)\n",
    "print(response.status_code)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ca64b80-042f-44c5-a611-8e761129d179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Make sure you have the right endpoint '/api/hello' defined in your App, here we used Python Flask framework to define the App content. You can also use node.js, django, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b66abe-d4fa-43e3-b380-bdd363ea25f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://dfci-api-management.azure-api.net/api2/v1/api/hello'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {token}',\n",
    "    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "}\n",
    "data = {'req': 'analyze ASML stock'}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=data)\n",
    "display(response.status_code)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9406ab8f-05d4-4c27-beb8-02b8cd108bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dir(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aafe6b1c-a726-40bd-9146-02110a664e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "displayHTML(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1253a58b-b5c8-452d-af71-bd45cb1ef5de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. Custom pyfunc model and Mlflow logging model to UC catalog, then use databricks model serving endpoint to serve it\n",
    "\n",
    "## Now we will work on the \"Databricks Model Serving Endpoint and Gateway\" module.\n",
    "\n",
    "The general workflow is:\n",
    "databricks notebook calling (client side) -> Databricks model serving endpoint with AI gateway -> getting Azure OAuth 2.0 servier token -> calling the API managed by APIM.\n",
    "\n",
    "We have 3 modules to write:\n",
    "1. defining pyfunc for logging customized model into UC catalog, which can getting OAuth token and can call Azure APIM using get and post request method\n",
    "2. logging the model to UC catalog\n",
    "3. setting up the databricks model serving endpoint with this customized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "961dd476-7049-4f42-a6bc-3e4a8bad2eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdc35af0-94e7-4ab0-8fca-90b6e2f80476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## We need to setup environment variables correctly.\n",
    "1. Locate your Azure Web App's credentials and API scope\n",
    "2. Locate your OAuth 2.0 Token URL\n",
    "3. Locate your APIM URL for the specific App's API managed by the APIM\n",
    "\n",
    "Fill in below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ebe5f5a-071b-44bc-a64a-8e4dedc0c95e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup env variables"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# OAuth 2.0 scopes provide a way to limit the amount of access that is granted to an access token. For example, an access token issued to a client app may be granted READ and WRITE access to protected resources, or just READ access. You can implement your APIs to enforce any scope or combination of scopes you wish.\n",
    "\n",
    "#: make sure you have all credentials and configs setup correctly in the os.environ variables.\n",
    "os.environ[\"TENANT_ID\"] = tenant_id = '9f37a392-f0ae-4280-9796-f1864a10effc'\n",
    "os.environ[\"OAUTH_TOKEN_URL\"] = oauth_token_url = f'https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token'\n",
    "os.environ[\"CLIENT_ID\"] = client_id = '610ad44b-74fc-4f7e-b385-cc8c93a8423b' # web app \"dfci-demo-app/fernet-w-api\" (slot)\n",
    "os.environ[\"CLIENT_SECRET\"] = client_secret # TODO: use db keyvault\n",
    "os.environ[\"API_SCOPE\"] = api_scope = \"api://610ad44b-74fc-4f7e-b385-cc8c93a8423b/.default\"\n",
    "# here APIM_URL includes api name and version already. later we just need to provide action/endpoint like /hello or /api/hello\n",
    "os.environ[\"APIM_URL\"] = apim_url = 'https://dfci-api-management.azure-api.net/api2/v1' # make sure no ending '/' for later syntax compliance, e.g., we dont want to have double slash in the url string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97ece54d-8fe7-4c07-be5c-6bb1e5fbd80a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the pyfunc custom PythonModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d1e905-d7f2-4d03-986e-ff8dafe84799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import mlflow\n",
    "# import openai\n",
    "import pandas as pd\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "# While both methods are used for initialization, __init__ is the standard constructor for Python classes, and load_context is specific to mlflow.pyfunc.PythonModel for loading model-related resources when the model is loaded from storage.\n",
    "\n",
    "class AzureAPIMModel(PythonModel):\n",
    "    def __init__(self):\n",
    "        self.oauth_token_url = os.environ[\"OAUTH_TOKEN_URL\"]\n",
    "        self.tenant_id = os.environ[\"TENANT_ID\"]\n",
    "        self.client_id = os.environ[\"CLIENT_ID\"]\n",
    "        self.client_secret = os.environ[\"CLIENT_SECRET\"]\n",
    "        self.api_scope = os.environ[\"API_SCOPE\"]\n",
    "        self.apim_url = os.environ[\"APIM_URL\"]\n",
    "    \n",
    "    def load_context(self, context):       \n",
    "        pass\n",
    "        #: if needed, uncomment below\n",
    "        # # Load artifacts or perform initialization tasks\n",
    "        # self.model = context.artifacts[\"my_model\"]\n",
    "        # self.api_key = context.artifacts[\"api_key\"]\n",
    "\n",
    "    def get_oauth_token(self):\n",
    "        payload = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'client_id': self.client_id,\n",
    "            'client_secret': self.client_secret,\n",
    "            'scope': self.api_scope\n",
    "        }\n",
    "        response = requests.post(self.oauth_token_url, data=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['access_token']\n",
    "\n",
    "    def _call_apim(self, method: str = 'get', endpoint: str = None, headers: dict = {}, data: dict = {'req': 'example query'}):\n",
    "        \"\"\"\n",
    "        This method calls the Azure API Management (APIM) endpoint with the specified HTTP method, endpoint, headers, and data.\n",
    "\n",
    "        Args:\n",
    "            method (str): The HTTP method to use for the request ('get' or 'post').\n",
    "            endpoint (str): The specific API endpoint to call.\n",
    "            headers (dict): Additional headers to include in the request.\n",
    "            data (dict): The data payload to send with the request.\n",
    "\n",
    "        Returns:\n",
    "            str: The response content from the APIM call.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unsupported HTTP method is provided.\n",
    "            requests.exceptions.HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "        \"\"\"\n",
    "        if method.lower() not in ('get', 'post'):\n",
    "            raise ValueError(\"Method value must be one of ('get', 'post')\")\n",
    "        token = self.get_oauth_token()\n",
    "        headers = headers or {} # inherit other headers users specified\n",
    "        headers['Authorization'] = f'Bearer {token}'\n",
    "        if method.lower() == 'get':\n",
    "            url = f\"{self.apim_url}/\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "        elif method.lower() == 'post':\n",
    "            # this depends on how your Flask app handles the request, e.g., req = request.form.get('req'), then you have to use application/x-www-form-urlencoded.\n",
    "            headers['Content-Type'] = 'application/x-www-form-urlencoded' \n",
    "            url = f\"{self.apim_url}{endpoint}\"\n",
    "            print(url)\n",
    "            response = requests.post(url, headers=headers, data=data)\n",
    "            # response = requests.post(url, headers=headers, json=data) # this is for 'application/json' format\n",
    "            # response.content.decode('utf-8')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method\")\n",
    "\n",
    "        response.raise_for_status()\n",
    "        return response.content.decode('utf-8')\n",
    "\n",
    "    def predict(self, context: dict, model_input: pd.Series[str] = pd.Series(['Please analyze NVIDIA stock'])) -> pd.Series:\n",
    "    # def predict(self, context, model_input = \"Please analyze NVIDIA stock\"):\n",
    "\n",
    "        responses = [self._call_apim(method = 'post', endpoint = '/api/hello', data = {'req': model_input[i]}) for i in range(len(model_input)) ]\n",
    "\n",
    "        return pd.Series(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6209e610-0340-4094-b241-e6075afc9cb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### dry test the class and instantiated the class object for inference without setting up model serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b61ea0f2-4bc3-441e-a02f-a2e2ab171d97",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test if the class works as expected"
    }
   },
   "outputs": [],
   "source": [
    "#: assume all os.environ is set correctly.\n",
    "\n",
    "# Instantiate the AzureAPIMModel class\n",
    "model = AzureAPIMModel()\n",
    "\n",
    "# Example input for prediction\n",
    "model_input = pd.Seriesy(['Please analyze BABA, Could you also analyze MAMA?', 'I would like to learn more about SON'])\n",
    "\n",
    "# Call the predict method\n",
    "predictions = model.predict(context = None, model_input = model_input)\n",
    "\n",
    "# Display the predictions\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9a3bd13-0c63-4d4f-b094-bbcfdce3745e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "displayHTML(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc8144a3-5cdd-476f-aa60-8a12291f157c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Now it is time to Mlflow log your custom model into the UC Catalog, so later you can serve it form model serving endpoint\n",
    "\n",
    "1. Model name should follow the hierarchy format of **\"catalog.schema.model_name\"**\n",
    "2. You will need the Databricks PAT or SP credentials for below operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7424454-06a0-4b26-ae32-1ac2176f90e3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "set up Databricks token for authentication"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['DATABRICKS_TOKEN'] = dbutils.secrets.get(scope=\"yyang_secret_scope\", key=\"pat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b02512c-68b1-449d-b552-ecf727541ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "signature=mlflow.models.infer_signature(model_input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be5bdee-c54f-4ba2-b40a-bd8d498d4600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b2c674-4eb8-4a34-951c-e9644cbdea12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "log and register pyfunc model with mlflow"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"azure_apim_model\",\n",
    "        signature = signature,\n",
    "        input_example=model_input[0],\n",
    "        python_model=AzureAPIMModel(),\n",
    "        registered_model_name=\"yyang.dfci_demo.DFCI_AzureAPIMModel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "262c5e41-aacf-49b7-ae63-c3a02fc0f526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### test loading directly from UC catalog and do batch inference (without model serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4d2911e-3f44-462c-a182-d5fa4653d6cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_input = \"Please analyze TSM stock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6768c35-5bb7-4da4-a4a4-a99b602df37a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Load the model\n",
    "model_name = \"yyang.dfci_demo.DFCI_AzureAPIMModel\"\n",
    "model_version = 9\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78bc9f7-721f-4c08-a2b8-6d795b826e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example input for prediction\n",
    "example_input = model_input  # Assuming model_input is defined in previous cells\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(example_input)\n",
    "\n",
    "# Display predictions\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4fcd12-838c-4068-bdf7-8658b9b4fe63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "displayHTML(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77144f49-176d-425a-afbb-849193d254d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create your Model Serving Endpoint programmatically\n",
    "Alternatively you can create it using UI interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c1b1c1-c0c7-43e0-9db3-61fa1400d2b9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "create Databricks model serving endpoint"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "client.create_endpoint(\n",
    "    name=\"azure-apim-serving-endpoint\",\n",
    "    config={\n",
    "        \"served_models\": [{\n",
    "            \"name\": \"DFCI_AzureAPIMModel\",\n",
    "            \"model_name\": \"yyang.dfci_demo.DFCI_AzureAPIMModel\",\n",
    "            \"model_version\": \"1\",\n",
    "            \"workload_size\": \"Small\",\n",
    "            \"scale_to_zero_enabled\": True\n",
    "        }]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3751f97a-9566-4d2e-98c0-5f41df72712b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "real-time check model serving endpoint creation status"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "# Define the endpoint status URL\n",
    "status_url = f\"https://adb-984752964297111.11.azuredatabricks.net/api/2.0/serving-endpoints/azure-apim-serving-endpoint\"\n",
    "\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['DATABRICKS_TOKEN']}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Function to check the endpoint status\n",
    "def check_status():\n",
    "    status_response = requests.get(status_url, headers=headers)\n",
    "    status_response.raise_for_status()\n",
    "    return status_response.json()\n",
    "\n",
    "# Loop to check the status periodically\n",
    "while True:\n",
    "    status = check_status()\n",
    "    state = status.get(\"state\", {}).get(\"ready\", \"UNKNOWN\")\n",
    "    \n",
    "    if state == \"READY\":\n",
    "        print(\"The endpoint creation has succeeded.\")\n",
    "        break\n",
    "    elif state == \"PENDING\":\n",
    "        print(\"The endpoint creation is still pending.\")\n",
    "    else:\n",
    "        print(f\"Current status: {state}\")\n",
    "    \n",
    "    time.sleep(30)  # Wait for 30 seconds before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07852a19-c47c-4d5f-98d4-d8a23e33f456",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "update serving endpoint configuration with version X model"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "client.update_endpoint(\n",
    "    endpoint=\"azure-apim-serving-endpoint\",\n",
    "    config={\n",
    "        \"served_models\": [{\n",
    "            \"name\": \"DFCI_AzureAPIMModel\",\n",
    "            \"model_name\": \"yyang.dfci_demo.DFCI_AzureAPIMModel\",\n",
    "            \"model_version\": \"9\",\n",
    "            \"workload_size\": \"Small\",\n",
    "            \"scale_to_zero_enabled\": True\n",
    "        }]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12afe903-9dbb-4cc7-96c6-7e69e192f5ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Make sure you have model serving endpoint ready before next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c670205c-ed19-40ab-8e02-48f2742d1c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. Query your model hosted on the Model Serving Endpoint for Inference\n",
    "\n",
    "Model Serving offers a unified REST API and MLflow Deployment API for CRUD and querying tasks.\n",
    "\n",
    "There are multiple ways to query the endpoint, including\n",
    "1. python script\n",
    "2. curl command\n",
    "3. SQL ai_query function\n",
    "4. UI\n",
    "\n",
    "Here, since it is in python notebook, we show the example of \"1. python script\" with two syntax. Feel free to use either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992793b3-052a-4489-b9a0-85c5be09f746",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "set up Databricks token for authentication"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['DATABRICKS_TOKEN'] = dbutils.secrets.get(scope=\"yyang_secret_scope\", key=\"pat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d9ab121-b2d3-4e66-b09e-f58645d48576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Syntax A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74f1b4b7-bfb0-4482-a6d0-3a00469dd816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "    return {'inputs': {name: data[name].tolist() for name in data.keys()} if isinstance(data, dict) else data.tolist()}\n",
    "\n",
    "def score_model(dataset):\n",
    "    url = 'https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/azure-apim-serving-endpoint/invocations'\n",
    "    headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN\")}', 'Content-Type': 'application/json'}\n",
    "    ds_dict = {'dataframe_split': dataset.to_dict(orient='split')} if isinstance(dataset, pd.DataFrame) else create_tf_serving_json(dataset)\n",
    "    data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40da5bd8-56f8-4056-897b-5c8b6e84bd58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = score_model( pd.Series(['Please analyze TSM stock']))\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "827327a7-a58d-4b0c-baa9-7313cdffeb5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "displayHTML(result.get('predictions')[0]['0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00736fa2-b752-4540-8faf-d62bbfb31de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Syntax B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72615f27-5b2e-4886-833d-e7b8c35ae429",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def score_model(data):\n",
    "    url = 'https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/azure-apim-serving-endpoint/invocations'\n",
    "    headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN\")}', 'Content-Type': 'application/json'}\n",
    "    data_json = json.dumps({\"inputs\": [data]})\n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7dabd1-c2f0-4704-9574-fb23646e91e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = score_model('Please analyze Netflix stock')\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6f196a-c701-4bd0-b017-63633cb1f59b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "displayHTML(result.get('predictions')[0]['0'])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1242762840109206,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "DFCI-Demo-App-Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
